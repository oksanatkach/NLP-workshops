{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "import math\n",
    "import operator\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_table('spam.csv', encoding='latin-1', header=0, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = full_df[['v1','v2']]\n",
    "df.columns = ['class', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  class                                               text\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...', 'Ok lar... Joking wif u oni...', \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\", 'U dun say so early hor... U c already then say...', \"Nah I don't think he goes to usf, he lives around here though\"]\n",
      "[['Go', 'until', 'jurong', 'point', ',', 'crazy..', 'Available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', '...', 'Cine', 'there', 'got', 'amore', 'wat', '...'], ['Ok', 'lar', '...', 'Joking', 'wif', 'u', 'oni', '...'], ['Free', 'entry', 'in', '2', 'a', 'wkly', 'comp', 'to', 'win', 'FA', 'Cup', 'final', 'tkts', '21st', 'May', '2005', '.', 'Text', 'FA', 'to', '87121', 'to', 'receive', 'entry', 'question', '(', 'std', 'txt', 'rate', ')', 'T', '&', 'C', \"'s\", 'apply', '08452810075over18', \"'s\"], ['U', 'dun', 'say', 'so', 'early', 'hor', '...', 'U', 'c', 'already', 'then', 'say', '...'], ['Nah', 'I', 'do', \"n't\", 'think', 'he', 'goes', 'to', 'usf', ',', 'he', 'lives', 'around', 'here', 'though']]\n",
      "['go', 'until', 'jurong', 'point', ',', 'crazy..', 'available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', '...', 'cine', 'there', 'got', 'amore', 'wat', '...', 'ok', 'lar', '...', 'joking', 'wif', 'u', 'oni', '...', 'free', 'entry', 'in', '2', 'a', 'wkly', 'comp', 'to', 'win', 'fa', 'cup', 'final', 'tkts', '21st', 'may', '2005', '.', 'text', 'fa', 'to', '87121', 'to', 'receive', 'entry', 'question', '(', 'std', 'txt', 'rate', ')', 't', '&', 'c', \"'s\", 'apply', '08452810075over18', \"'s\", 'u', 'dun', 'say', 'so', 'early', 'hor', '...', 'u', 'c', 'already', 'then', 'say', '...', 'nah', 'i', 'do', \"n't\", 'think', 'he', 'goes', 'to', 'usf', ',', 'he', 'lives', 'around', 'here', 'though']\n",
      "{'08452810075over18', 'oni', '...', 'so', 'crazy..', 'there', 'early', 'comp', 'usf', 'around', 'here', 't', 'say', 'available', 'only', '.', 'wif', 'do', 'think', 'question', 'rate', 'final', 'goes', 'wat', 'la', 'cine', 'text', 'until', 'point', 'in', 'got', 'receive', 'lar', \"'s\", 'go', 'ok', 'entry', '2005', '2', 'to', '(', 'buffet', 'amore', 'txt', 'apply', ')', 'wkly', 'may', 'bugis', 'hor', 'dun', 'though', 'he', 'u', 'cup', 'jurong', 'e', '87121', 'c', 'i', 'nah', 'win', '21st', 'n', \"n't\", 'fa', 'then', 'lives', 'world', 'joking', ',', 'great', 'a', 'std', '&', 'tkts', 'already', 'free'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sents = df.head()['text'].tolist()\n",
    "\n",
    "words = [ word_tokenize(sent) for sent in sents ]\n",
    "collapse = [ word.lower() for sent in words for word in sent ]\n",
    "\n",
    "print(sents)\n",
    "print(words)\n",
    "print(collapse)\n",
    "print(set(collapse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(df):\n",
    "    \n",
    "    spam_sents = df.loc[df['class'] == 'spam']['text'].tolist()\n",
    "    ham_sents = df.loc[df['class'] == 'ham']['text'].tolist()\n",
    "    shuffle(spam_sents)\n",
    "    shuffle(ham_sents)\n",
    "    \n",
    "    spam_words = [ word_tokenize(sent) for sent in spam_sents ]\n",
    "    spam_collapse = [ word.lower() for sent in spam_words for word in sent ]\n",
    "    ham_words = [ word_tokenize(sent) for sent in ham_sents ]\n",
    "    ham_collapse = [ word.lower() for sent in ham_words for word in sent ]\n",
    "    \n",
    "    labels = df['class'].tolist()\n",
    "    sents = df['text'].tolist()\n",
    "    \n",
    "    words = spam_collapse + ham_collapse\n",
    "    \n",
    "    n = int(0.8*len(labels))\n",
    "    \n",
    "    return labels[:n], labels[n:], sents[:n], sents[n:], set(words), spam_collapse, ham_collapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test, X_train, X_test, vocab, spam_words, ham_words = prep_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior probability * likelyhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def priors(labels):\n",
    "    return { cl: math.log(float(labels.count(cl)) / len(labels)) for cl in labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ham': -0.1451048869491259, 'spam': -2.0019737276377345}\n"
     ]
    }
   ],
   "source": [
    "priors = priors(y_train)\n",
    "print(priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(vocab, spam_words, ham_words):\n",
    "    ALL = spam_words + ham_words\n",
    "    mles = {'spam': {}, 'ham': {}}\n",
    "    \n",
    "    for word in vocab:\n",
    "        mles['spam'][word] = math.log((spam_words.count(word) + 1) / float((ALL.count(word) + len(vocab))))\n",
    "        mles['ham'][word] = math.log((ham_words.count(word) + 1) / float((ALL.count(word) + len(vocab))))\n",
    "    \n",
    "    return mles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "mles = likelihood(vocab, spam_words, ham_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaiveBayes(priors, mles, sent):\n",
    "    preds = {}\n",
    "    for cl in mles.keys():\n",
    "        pred = priors[cl]\n",
    "        words = word_tokenize(sent)\n",
    "        for word in words:\n",
    "            if word in mles[cl].keys():\n",
    "                pred += mles[cl][word]\n",
    "        preds[cl] = pred\n",
    "    return max(preds.items(), key=operator.itemgetter(1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NaiveBayes(priors, mles,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6448598130841121\n"
     ]
    }
   ],
   "source": [
    "def counts(x, label):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    tn = 0\n",
    "    for ind in range(len(x)):\n",
    "        pred_l = NaiveBayes(priors, mles, x[ind])\n",
    "        #print(sent)\n",
    "        #print(pred_l)\n",
    "        if pred_l == label:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    return tp, fp\n",
    "\n",
    "spam = []\n",
    "ham = []\n",
    "for ind in range(len(X_test)):\n",
    "    if y_test[ind] == 'spam':\n",
    "        spam.append(X_test[ind])\n",
    "    else:\n",
    "        ham.append(X_test[ind])\n",
    "\n",
    "sp_tp, sp_fp = counts(spam, 'spam')\n",
    "sp_tn, sp_fn = counts(ham, 'ham')\n",
    "\n",
    "#print(len(X_test))\n",
    "# accuracy = float(tp)/len(y_test)\n",
    "\n",
    "sp_precision = float(sp_tp)/(sp_tp+sp_fp)\n",
    "sp_accuracy = float(sp_tp+sp_tn)/len(y_test)\n",
    "sp_recall = float(sp_tp)/(sp_tp+sp_fn)\n",
    "f1 = ((sp_precision * sp_recall)/(sp_precision + sp_recall)) * 2\n",
    "\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
